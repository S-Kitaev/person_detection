{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4b3bd4",
   "metadata": {},
   "source": [
    "### Проведем инференс модели RF-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d267281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from rfdetr import RFDETRBase\n",
    "# from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4dc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "from inference_functions.yolo_inf_functions import target_boxes\n",
    "from inference_functions.yolo_inf_functions import check_class, check_class_rtdetr\n",
    "from inference_functions.yolo_inf_functions import clip_box, map50_calculate\n",
    "from inference_functions.yolo_inf_functions import read_reference_video_rfdetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac57053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_IMAGES_DIR : data/test/test\n",
      "ANNOTATIONS_CSV : data/test/test/_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGES_DIR = \"data/test/test\"\n",
    "ANNOTATIONS_CSV = \"data/test/test/_annotations.csv\"\n",
    "CONF_THRESH = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "print(\"TEST_IMAGES_DIR :\", TEST_IMAGES_DIR)\n",
    "print(\"ANNOTATIONS_CSV :\", ANNOTATIONS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a711dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных изображений в CSV: 738, общее число bbox: 2783\n"
     ]
    }
   ],
   "source": [
    "# Загружаем истинные метки областей детекции из датасета\n",
    "target_boxes_dict = target_boxes(ANNOTATIONS_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a31a28",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ac5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "person_class_idx = 1\n"
     ]
    }
   ],
   "source": [
    "model = RFDETRBase()\n",
    "# model.optimize_for_inference(compile=False)\n",
    "\n",
    "person_class_idx = check_class_rtdetr(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb0f8b",
   "metadata": {},
   "source": [
    "### Сбор предсказаний модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08c7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF-DETR inference on test images:   0%|          | 0/738 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4319.)\n",
      "RF-DETR inference on test images: 100%|██████████| 738/738 [36:32<00:00,  2.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего предсказаний (person) собрано: 2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "def find_image_path(fname):\n",
    "    '''\n",
    "    Поиск необходимого файла\n",
    "    '''\n",
    "\n",
    "    p2 = TEST_IMAGES_DIR + '/' + fname\n",
    "    return p2\n",
    "\n",
    "image_list = list(target_boxes_dict.keys())\n",
    "\n",
    "# Цикл сбора предсказаний\n",
    "for fname in tqdm(image_list, desc=\"RF-DETR inference on test images\"):\n",
    "    img_path = find_image_path(fname)\n",
    "    if img_path is None:\n",
    "        print(f\"Image not found, skipping: {fname}\")\n",
    "        continue\n",
    "    \n",
    "    pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "    detections = model.predict(pil_img, threshold=float(CONF_THRESH))\n",
    "    det = detections[0] if isinstance(detections, (list, tuple)) else detections\n",
    "\n",
    "    if not hasattr(det, \"xyxy\") or len(det.xyxy) == 0:\n",
    "        continue\n",
    "\n",
    "    img_w, img_h = pil_img.size\n",
    "\n",
    "    xyxys = np.array(det.xyxy)\n",
    "    scores = np.array(det.confidence)\n",
    "    classes = np.array(det.class_id)\n",
    "\n",
    "    for box, score, cls in zip(xyxys, scores, classes):\n",
    "        cls_int = int(cls)\n",
    "        if cls_int != person_class_idx:\n",
    "            continue\n",
    "        \n",
    "        xyxy = [int(box[0]), int(box[1]), int(box[2]), int(box[3])]\n",
    "        xyxy = clip_box(xyxy, img_w, img_h)\n",
    "        preds.append({\n",
    "            'image_id': fname,\n",
    "            'score': float(score),\n",
    "            'bbox': xyxy\n",
    "        })\n",
    "\n",
    "print(f\"Всего предсказаний (person) собрано: {len(preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83064bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50 для датасета = 0.5384\n"
     ]
    }
   ],
   "source": [
    "map50_calculate(preds, target_boxes_dict, IOU_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dccaf0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video inference: 100%|██████████| 705/705 [33:13<00:00,  2.83s/frame]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео с детекцие сохранено в reference video/detected_persons/4_rt-detr_detected_crowd.mp4. Кадров обработано: 705, отрисовано bbox: 7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_path = \"reference video/crowd.mp4\"\n",
    "save_video_path = \"reference video/detected_persons/4_rt-detr_detected_crowd.mp4\"\n",
    "\n",
    "read_reference_video_rfdetr(model, video_path, save_video_path, person_class_idx, conf_thresh=CONF_THRESH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
