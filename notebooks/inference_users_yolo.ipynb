{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f56f304",
   "metadata": {},
   "source": [
    "### Проведем инференс предобученной модели YOLO на датасете по обнаружению людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41364187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2db83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "from inference_functions.yolo_inf_functions import target_boxes\n",
    "from inference_functions.yolo_inf_functions import check_class\n",
    "from inference_functions.yolo_inf_functions import clip_box, map50_calculate\n",
    "from inference_functions.yolo_inf_functions import read_reference_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a4b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_IMAGES_DIR : data/test/test\n",
      "ANNOTATIONS_CSV : data/test/test/_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGES_DIR = \"data/test/test\"\n",
    "ANNOTATIONS_CSV = \"data/test/test/_annotations.csv\"\n",
    "CONF_THRESH = 0.001\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "print(\"TEST_IMAGES_DIR :\", TEST_IMAGES_DIR)\n",
    "print(\"ANNOTATIONS_CSV :\", ANNOTATIONS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9356732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных изображений в CSV: 738, общее число bbox: 2783\n"
     ]
    }
   ],
   "source": [
    "# Загружаем истинные метки областей детекции из датасета\n",
    "target_boxes_dict = target_boxes(ANNOTATIONS_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212cd60",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661275ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден индекс класса 'person' = 0 (в model.names).\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"models/weights/3_yolo_users.pt\")\n",
    "\n",
    "# проверяем есть в модели класс person\n",
    "person_class_idx = check_class(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2937f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on test images: 100%|██████████| 738/738 [05:09<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего предсказаний (person) собрано: 17542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "def find_image_path(fname):\n",
    "    '''Поиск необходимого файла'''\n",
    "    p2 = TEST_IMAGES_DIR + '/' + fname\n",
    "    return p2\n",
    "\n",
    "image_list = list(target_boxes_dict.keys())\n",
    "\n",
    "# Цикл сбора предсказаний\n",
    "for fname in tqdm(image_list, desc=\"Running inference on test images\"):\n",
    "\n",
    "    img_path = find_image_path(fname)\n",
    "    results = model.predict(source=str(img_path), conf=CONF_THRESH, imgsz=640, verbose=False)\n",
    "\n",
    "    if len(results) == 0:\n",
    "        continue\n",
    "    r = results[0]\n",
    "\n",
    "    boxes = getattr(r.boxes, \"xyxy\", None)\n",
    "    scores = getattr(r.boxes, \"conf\", None)\n",
    "    classes = getattr(r.boxes, \"cls\", None)\n",
    "\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    img_h, img_w = r.orig_shape[0], r.orig_shape[1]\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cls = int(classes[i].item()) if classes is not None else None\n",
    "        if cls is None:\n",
    "            continue\n",
    "        if cls != person_class_idx:\n",
    "            continue\n",
    "        xyxy = boxes[i].cpu().numpy().tolist()\n",
    "        score = float(scores[i].cpu().numpy().tolist()) if scores is not None else 1.0\n",
    "        xyxy = clip_box(xyxy, img_w, img_h)\n",
    "        preds.append({\n",
    "            'image_id': fname,\n",
    "            'score': score,\n",
    "            'bbox': xyxy\n",
    "        })\n",
    "\n",
    "print(f\"Всего предсказаний (person) собрано: {len(preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e1d07",
   "metadata": {},
   "source": [
    "### Расчет MAP50 метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54daabd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50 для датасета = 0.4519\n"
     ]
    }
   ],
   "source": [
    "map50_calculate(preds, target_boxes_dict, IOU_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7954f9",
   "metadata": {},
   "source": [
    "### Сохраняем готовое видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff398607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video inference: 100%|██████████| 705/705 [05:02<00:00,  2.33frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео с детекцией сохранено в reference video/detected_persons/3_yolo_users_detected_crowd.mp4. Кадров обработано: 705, отрисовано bbox: 9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_path = \"reference video/crowd.mp4\"\n",
    "save_video_path = \"reference video/detected_persons/3_yolo_users_detected_crowd.mp4\"\n",
    "\n",
    "read_reference_video(model, video_path, save_video_path, person_class_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
